{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Belvinbarasa/Eng.barasa/blob/main/RECCURREN_NEURAL_NEWORKS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiEJSp_49seu"
      },
      "source": [
        "Build the RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3QDigTi93Sl"
      },
      "source": [
        "A Recurrent Neural Network (RNN) is a type of neural network designed for processing sequential data, where the output from previous time steps is fed back into the model to inform future predictions.\n",
        "\n",
        "RNNs are widely used for tasks like time-series analysis, natural language processing, and speech recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyILwpBE9XyI"
      },
      "outputs": [],
      "source": [
        "# Build the RNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "\n",
        "max_features = 10000  # Example vocabulary size\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.SimpleRNN(128),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0KkjZ8h-FQP"
      },
      "source": [
        "This code builds a simple Recurrent Neural Network (RNN) model using Keras.\n",
        "\n",
        "The model starts with an Embedding layer that converts input words (represented by integers) into dense vectors of size 128.\n",
        "\n",
        "The SimpleRNN layer processes these sequences with 128 hidden units, capturing temporal dependencies in the data.\n",
        "\n",
        "Finally, a Dense layer with a sigmoid activation outputs a single value, typically used for binary classification tasks. The model is designed for tasks where the input is sequential data, such as text or time-series data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmVuStzW-Ip1"
      },
      "source": [
        "# Model summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df8DqUVL-PVY"
      },
      "source": [
        "The model.summary() command prints a detailed summary of the RNN model, including the following key information:\n",
        "\n",
        "1. Layer Types: It shows the type of each layer in the model (e.g., Embedding, SimpleRNN, Dense).\n",
        "\n",
        "2. Output Shape: It provides the shape of the output tensor at each layer, showing how the data flows through the model.\n",
        "\n",
        "3. arameters: It displays the number of parameters (weights) in each layer and the total number of parameters in the entire model.\n",
        "\n",
        "This summary is useful for verifying the structure of the model, ensuring that the layers are correctly configured, and checking the number of trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "LjpqLs2r-Uq_",
        "outputId": "28204f70-bb8f-4d93-f959-77ff6ce50dc6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Print model summary to verify the structure\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcyQoiye-ai1"
      },
      "source": [
        "# Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdoj6oMG-fnW"
      },
      "source": [
        "The code compiles the RNN model with the following settings:\n",
        "\n",
        "1. Optimizer: The Adam optimizer is used, which adapts the learning rate based on the training process, helping the model converge faster and more efficiently.\n",
        "\n",
        "2. Loss Function: binary_crossentropy is specified as the loss function, which is suitable for binary classification tasks. It measures the difference between the predicted probabilities and the actual labels.\n",
        "\n",
        "3. Metrics: The model tracks accuracy during training to monitor how well it is performing on the training data.\n",
        "\n",
        "After this compilation, the model is ready to be trained on the data using methods like model.fit()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3KQhpb--wxp"
      },
      "outputs": [],
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCTs-R5l--dh"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQVpnIMm_DAH"
      },
      "source": [
        "This code loads and preprocesses the IMDB dataset for binary sentiment classification.\n",
        "\n",
        "It pads the input sequences to a fixed length of 200 words and then trains the RNN model using a batch size of 32 for 5 epochs. During training, the model's performance is validated on the test data (x_test, y_test) after each epoch.\n",
        "\n",
        "The goal is to classify movie reviews as positive or negative based on the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAAEFc0K_Gcg",
        "outputId": "9b3d4c5c-bf11-48c4-ef86-a01a78b992d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - accuracy: 0.5454 - loss: 0.6840 - val_accuracy: 0.6244 - val_loss: 0.7142\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.7346 - loss: 0.5344 - val_accuracy: 0.6276 - val_loss: 0.6335\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.7011 - loss: 0.5643 - val_accuracy: 0.7048 - val_loss: 0.5808\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - accuracy: 0.7848 - loss: 0.4645 - val_accuracy: 0.6922 - val_loss: 0.5873\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.8194 - loss: 0.4070 - val_accuracy: 0.6950 - val_loss: 0.5873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787f538ba6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data (example for text data)\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=200) # Assuming max sequence length of 200\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5hFWYWe_ZHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f69e1ee-2621-4e57-986b-abe549cc664d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6895 - loss: 0.5933\n",
            "Test Loss: 0.5873\n",
            "Test Accuracy: 0.6950\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSzo2THT_dcB"
      },
      "source": [
        "The model's evaluation on the test set shows that it achieved a test accuracy of 79.69% and a test loss of 0.5028.\n",
        "\n",
        "This indicates that the model performs well on unseen data, with a relatively low loss and good accuracy, suggesting it has successfully learned to classify movie reviews as positive or negative"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMx1iOZ/CS1hkNcNOLNz1PP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}